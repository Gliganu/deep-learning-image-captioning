{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding,GRU,TimeDistributed,RepeatVector,Merge,BatchNormalization,Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Embedding,LSTM,GRU,TimeDistributed,RepeatVector,Merge,Input,merge,UpSampling2D\n",
    "from keras.preprocessing import sequence\n",
    "from keras import callbacks\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "import numpy as np\n",
    "from vgg16 import Vgg16\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import cPickle as pickle\n",
    "import string\n",
    "\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from numpy.random import random, permutation, randn, normal \n",
    "\n",
    "import os\n",
    "\n",
    "import preprocessing as preproc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vgg_model():\n",
    "    image_model = Vgg16().model\n",
    "    image_model.pop()\n",
    "    image_model.pop()\n",
    "    image_model.trainable = False\n",
    "    image_model.add(RepeatVector(MAX_CAPTION_LEN))\n",
    "    return image_model\n",
    "\n",
    "def get_precomputed_input_model():\n",
    "    input_model = Sequential()\n",
    "    input_model.add(RepeatVector(MAX_CAPTION_LEN,input_shape=(4096,)))\n",
    "    return input_model\n",
    "\n",
    "# GRU\n",
    "\n",
    "def get_language_model(emb):\n",
    "    language_model = Sequential()\n",
    "    language_model.add(Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_CAPTION_LEN,weights=[emb]))\n",
    "    Dropout(0.5)\n",
    "    language_model.add(BatchNormalization())\n",
    "    return language_model\n",
    "\n",
    "def get_reinforcement_model():\n",
    "    reinforcement_model = Sequential()\n",
    "    reinforcement_model.add(Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_CAPTION_LEN,weights=[emb]))\n",
    "    Dropout(0.5)\n",
    "    reinforcement_model.add(BatchNormalization())\n",
    "    return reinforcement_model\n",
    "\n",
    "# Top level model\n",
    "\n",
    "def build_model(image_model,language_model,reinforcement_model):\n",
    "    model = Sequential()\n",
    "    model.add(Merge([image_model, language_model,reinforcement_model], mode='concat'))\n",
    "\n",
    "    model.add(GRU(1024,activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(GRU(1024,activation='relu', return_sequences=True))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(VOCAB_SIZE, activation = 'softmax')))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = Adam(0.001))\n",
    "    return model\n",
    "\n",
    "def get_vgg_features(img_name):\n",
    "    \n",
    "    full_img_name = base_img_folder+\"/\"+img_name\n",
    "    img = PIL.Image.open(full_img_name)\n",
    "    img = img.resize((224, 224), PIL.Image.NEAREST)\n",
    "    img = np.asarray(img)\n",
    "    \n",
    "    if(img.shape != (224,224,3)): #Black & White picture \n",
    "        img = np.expand_dims(img,axis=2)\n",
    "        img = np.concatenate([img,img,img],axis=2)\n",
    "        print(img.shape)\n",
    "        \n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "    vgg_features = vgg_model.predict(img)\n",
    "        \n",
    "    return vgg_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = data_path+\"app-100-length-15/\"\n",
    "MAX_CAPTION_LEN = 15 # ATENTIE AICI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_words = preproc.load_obj(base_path + general_datastruct_folder+\"unique_words\")\n",
    "word2index = preproc.load_obj(base_path+general_datastruct_folder+\"word2index\")\n",
    "index2word = preproc.load_obj(base_path+general_datastruct_folder+\"index2word\")\n",
    "VOCAB_SIZE = len(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EMB_SIZE = 300\n",
    "vecs, words, wordidx = preproc.load_vectors(save_path+glove_folder+\"6B.\"+str(EMB_SIZE)+\"d\")\n",
    "\n",
    "emb = preproc.create_emb(vecs, words, wordidx,index2word,VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_model = get_vgg_model()\n",
    "image_model = get_precomputed_input_model()\n",
    "language_model = get_language_model(emb)\n",
    "reinforcement_model = get_reinforcement_model()\n",
    "model = build_model(image_model,language_model,reinforcement_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(save_path + models_folder+\"big/\" +'app_100_length_15_past_word_20_epoch_300d_gru_2x1048_big.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final testing dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_img_folder = \"/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/raw_images/val2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_names = os.listdir(base_img_folder)\n",
    "img_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(img_names, columns = [\"img_name\"])\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df['vgg'] = data_df['img_name'].apply(get_vgg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_data_folder = \"/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/coco-validation/base-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.to_pickle(base_data_folder+\"all-valid-df.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle(base_data_folder+\"all-valid-df.p\")\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(vgg_features):\n",
    "    startIndex = word2index[\"START\"]\n",
    "    start_captions = [[startIndex]]\n",
    "    start_captions = sequence.pad_sequences(start_captions, maxlen=MAX_CAPTION_LEN,padding='post')\n",
    "\n",
    "    first_image_input = np.squeeze(vgg_features)[0].reshape(1,4096)\n",
    "    \n",
    "    firstCaption = np.expand_dims(start_captions[0], axis=0) \n",
    "    prev_word_indexed_captions = np.expand_dims(list(start_captions[0]), axis=0)\n",
    "    \n",
    "    outputs = []\n",
    "\n",
    "    endGenerated = False\n",
    "    i = 0\n",
    "        \n",
    "    while ((not endGenerated) & (i < MAX_CAPTION_LEN-1)):\n",
    "       \n",
    "        predictions = model.predict([first_image_input, firstCaption, prev_word_indexed_captions])\n",
    "        predictions = predictions[0]\n",
    "        \n",
    "        currentPred = predictions[i]\n",
    "        \n",
    "        max_index = np.argmax(currentPred)\n",
    "        \n",
    "        outputs.append(max_index)\n",
    "        firstCaption[0,i+1] = max_index\n",
    "        \n",
    "        prev_word_indexed_captions[0,i+1] = firstCaption[0,i]\n",
    "                \n",
    "        i+=1\n",
    "\n",
    "        if(index2word[max_index] == \"END\"):\n",
    "            endGenerated = True\n",
    "\n",
    "    caption = ' '.join([index2word[x] for x in firstCaption[0][1:i]])\n",
    "    \n",
    "    return caption\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df['caption'] = data_df['vgg'].apply(make_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df[\"caption\"].tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_img_id(path):\n",
    "    return long(path.split(\".\")[0].split(\"_\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df['image_id'] = data_df[\"img_name\"].apply(get_img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df[[\"image_id\",\"caption\"]].to_json(base_data_folder+\"all-valid-df-with-pred.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/coco-validation\")\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annFile='/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/coco-validation/annotations/captions_val2014.json'\n",
    "resFile = \"/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/coco-validation/base-data/all-valid-df-with-pred.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.649435\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# create coco object and cocoRes object\n",
    "coco = COCO(annFile)\n",
    "cocoRes = coco.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'reflen': 381670, 'guess': [381985, 341481, 300977, 260473], 'testlen': 381985, 'correct': [247171, 112227, 46585, 19826]}\n",
      "ratio: 1.0008253203\n",
      "Bleu_1: 0.647\n",
      "Bleu_2: 0.461\n",
      "Bleu_3: 0.320\n",
      "Bleu_4: 0.224\n",
      "computing METEOR score...\n",
      "METEOR: 0.212\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.473\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.679\n"
     ]
    }
   ],
   "source": [
    "# create cocoEval object by taking coco and cocoRes\n",
    "cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "\n",
    "# evaluate results\n",
    "cocoEval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
