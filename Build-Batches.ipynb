{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n",
      "/opt/conda/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.layers import Embedding,GRU,TimeDistributed,RepeatVector,Merge,BatchNormalization\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import numpy as np\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "from utils import *\n",
    "import cPickle as pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from numpy.random import random, permutation, randn, normal \n",
    "\n",
    "import os\n",
    "import preprocessing as preproc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unique_words(captions):\n",
    "    unique_words = []\n",
    "    words = [caption.split() for caption in captions]\n",
    "   \n",
    "    for word in words:\n",
    "        unique_words.extend(word)\n",
    "        \n",
    "    unique_words = list(set(unique_words))\n",
    "    \n",
    "    return unique_words\n",
    "\n",
    "def get_index_word_dicts(unique_words):\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "    for i,word in enumerate(unique_words):\n",
    "        word_index[word] = i\n",
    "        index_word[i] = word\n",
    "        \n",
    "    return (word_index,index_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = \"/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/\"\n",
    "\n",
    "annotation_path = save_path +\"raw_annotations/captions_val2014.json\"\n",
    "\n",
    "images_path = save_path+\"raw_images/val2014\"\n",
    "image_data_arr_path = save_path+\"imageDataArr/\"\n",
    "images_concat_t_path = save_path+\"imagesConcatT/\"\n",
    "captions_path = save_path+\"captions/\"\n",
    "temp_save_path = save_path+\"temp/\"\n",
    "model_path = save_path+\"models/\"\n",
    "images_vgg_features_path = save_path + \"images_vgg_features/\"\n",
    "\n",
    "train_path = save_path + \"train/\"\n",
    "test_path = save_path + \"test/\"\n",
    "\n",
    "\n",
    "images_concat_folder = \"images_concat/\"\n",
    "images_vgg_4096_folder = \"images_vgg_4096/\"\n",
    "captions_folder = \"captions/\"\n",
    "indexed_captions_folder = \"indexed-captions/\"\n",
    "indexed_future_words_folder = \"indexed-future-words/\"\n",
    "glove_folder = \"glove/\"\n",
    "\n",
    "misc_folder = \"misc/\"\n",
    "\n",
    "batch_folder = \"batches/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NR_TRAIN_INSTANCES = 10240\n",
    "BATCH_SIZE = 1024\n",
    "MAX_CAPTION_LEN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images_precomputed_vgg_features = preproc.read_serialized_np_arr(train_path+images_vgg_4096_folder+'vgg_features.bc'\n",
    "                                                                  ,nr_instances = NR_TRAIN_INSTANCES )\n",
    "\n",
    "print(train_images_precomputed_vgg_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_captions = preproc.get_truncated_captions_from_batch(train_path + captions_folder, batch_nr = 0,\n",
    "                                                           nr_instances = NR_TRAIN_INSTANCES )\n",
    "\n",
    "print(len(train_captions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save img vgg features batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(train_images_precomputed_vgg_features) / BATCH_SIZE)):\n",
    "    img_vgg_feature_list = []\n",
    "    \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        img_vgg_feature = np.expand_dims(train_images_precomputed_vgg_features[index*BATCH_SIZE + elem_in_batch],axis=0)\n",
    "        img_vgg_feature_list.append(img_vgg_feature)\n",
    "        \n",
    "    img_vgg_batch = np.vstack(img_vgg_feature_list)\n",
    "    save_array(train_path+batch_folder+images_vgg_4096_folder+'img_vgg_feature_'+str(format(index, \"06\"))+'_'+'.bc',\n",
    "               img_vgg_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save raw captions batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 57.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(train_captions)/BATCH_SIZE)):\n",
    "    caption_list = []\n",
    "    \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        caption_list.append(train_captions[index*BATCH_SIZE + elem_in_batch])\n",
    "     \n",
    "    captions_batch = np.vstack(caption_list)\n",
    "    \n",
    "    save_array(train_path+batch_folder+captions_folder+'caption_'+str(format(index, \"06\"))+'_'+'.bc',\n",
    "               captions_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save indexed captions batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10240it [00:00, 49993.92it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_words = get_unique_words(train_captions)\n",
    "VOCAB_SIZE = len(unique_words)\n",
    "(word2index, index2word) = get_index_word_dicts(unique_words)\n",
    "\n",
    "indexed_captions = []\n",
    "for index,train_caption in tqdm(enumerate(train_captions)):\n",
    "    indexed_caption = [word2index[caption_word] for caption_word in train_caption.split()]\n",
    "    indexed_caption = sequence.pad_sequences([indexed_caption], maxlen=MAX_CAPTION_LEN,padding='post')\n",
    "    indexed_np_arr = np.asarray(np.squeeze(indexed_caption))\n",
    "    \n",
    "    indexed_captions.append(indexed_np_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 54.95it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(indexed_captions)/BATCH_SIZE)):\n",
    "    \n",
    "    indexed_caption_list = []\n",
    "    \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        indexed_caption = np.expand_dims(indexed_captions[index*BATCH_SIZE + elem_in_batch],axis=0)\n",
    "        indexed_caption_list.append(indexed_caption)\n",
    "        \n",
    "    indexed_captions_batch = np.vstack(indexed_caption_list)\n",
    "    \n",
    "    save_array(train_path+batch_folder+indexed_captions_folder+'indexed_caption_'+str(format(index, \"06\"))+'_'+'.bc',\n",
    "               indexed_captions_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save future words captions batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 2235.13it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3086.74it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3101.24it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3076.79it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3228.22it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3190.08it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3232.62it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3074.41it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3225.08it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3248.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in (range(len(indexed_captions)/BATCH_SIZE)):\n",
    "\n",
    "    indexed_future_word_list = []\n",
    "        \n",
    "    for elem_in_batch in tqdm(range(BATCH_SIZE)):\n",
    "\n",
    "        caption_indexed = indexed_captions[index*BATCH_SIZE + elem_in_batch]\n",
    "            \n",
    "        enhanced_caption_indexed = np.append(caption_indexed,[word2index[\"END\"]]) #hacky\n",
    "        word_2_next_word = []\n",
    "\n",
    "        for i in xrange(0,len(caption_indexed)):\n",
    "            caption_word_index = enhanced_caption_indexed[i]\n",
    "            future_word_index = enhanced_caption_indexed[i+1]\n",
    "            future_indexes = np.zeros(VOCAB_SIZE)\n",
    "            future_indexes[future_word_index] = 1\n",
    "\n",
    "            word_2_next_word.append(future_indexes)\n",
    "\n",
    "        words_2_next_word = np.vstack(word_2_next_word)\n",
    "        words_2_next_word = np.expand_dims(words_2_next_word,axis=0)\n",
    "        \n",
    "        indexed_future_word_list.append(words_2_next_word)\n",
    "    \n",
    "    indexed_future_words_batch = np.vstack(indexed_future_word_list)\n",
    "    \n",
    "    save_array(train_path+batch_folder+indexed_future_words_folder+'indexed_future_word_'+str(format(index, \"06\"))+'_'+'.bc', \n",
    "               indexed_future_words_batch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving other misc data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.save_obj(unique_words,train_path+batch_folder+misc_folder+\"unique_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.save_obj(word2index,train_path+batch_folder+misc_folder+\"word2index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc.save_obj(index2word,train_path+batch_folder+misc_folder+\"index2word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
