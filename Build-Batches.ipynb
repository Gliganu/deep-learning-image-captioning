{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# import PIL.Image\n",
    "\n",
    "# import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from utils import *\n",
    "# import cPickle as pickle\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# from itertools import compress\n",
    "\n",
    "# import shutil\n",
    "# import string\n",
    "\n",
    "# import collections\n",
    "# import nltk\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# import re\n",
    "# from numpy.random import random, permutation, randn, normal \n",
    "\n",
    "# import os\n",
    "import preprocessing as preproc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unique_words(captions):\n",
    "    unique_words = []\n",
    "    words = [caption.split() for caption in captions]\n",
    "   \n",
    "    for word in words:\n",
    "        unique_words.extend(word)\n",
    "        \n",
    "    unique_words = list(set(unique_words))\n",
    "    \n",
    "    return unique_words\n",
    "\n",
    "def get_index_word_dicts(unique_words):\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "    for i,word in enumerate(unique_words):\n",
    "        word_index[word] = i\n",
    "        index_word[i] = word\n",
    "        \n",
    "    return (word_index,index_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = \"/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/\"\n",
    "\n",
    "train_path = save_path + \"train/\"\n",
    "test_path = save_path + \"test/\"\n",
    "\n",
    "images_vgg_4096_folder = \"images_vgg_4096/\"\n",
    "captions_folder = \"captions/\"\n",
    "indexed_captions_folder = \"indexed-captions/\"\n",
    "batch_folder = \"batches/\"\n",
    "indexed_future_words_folder = \"indexed-future-words/\"\n",
    "misc_folder = \"misc/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_path = test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NR_TRAIN_INSTANCES = 82000\n",
    "BATCH_SIZE = 500\n",
    "MAX_CAPTION_LEN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4096)\n"
     ]
    }
   ],
   "source": [
    "images_precomputed_vgg_features = preproc.read_serialized_np_arr(base_path+images_vgg_4096_folder+'vgg_features.bc'\n",
    "                                                                  ,nr_instances = NR_TRAIN_INSTANCES )\n",
    "\n",
    "print(images_precomputed_vgg_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "raw_captions = preproc.get_truncated_captions_from_batch(base_path + captions_folder, batch_nr = 0,\n",
    "                                                           nr_instances = NR_TRAIN_INSTANCES )\n",
    "\n",
    "print(len(raw_captions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save img vgg features batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 28.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(images_precomputed_vgg_features) / BATCH_SIZE)):\n",
    "    img_vgg_feature_list = []\n",
    "    \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        img_vgg_feature = np.expand_dims(images_precomputed_vgg_features[index*BATCH_SIZE + elem_in_batch],axis=0)\n",
    "        img_vgg_feature_list.append(img_vgg_feature)\n",
    "        \n",
    "    img_vgg_batch = np.vstack(img_vgg_feature_list)\n",
    "    save_array(base_path + batch_folder + images_vgg_4096_folder + 'img_vgg_feature_' + str(format(index, \"06\"))\n",
    "               + '_' + '.bc',img_vgg_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save raw captions batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 294.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(raw_captions)/BATCH_SIZE)):\n",
    "    caption_list = []\n",
    "    \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        caption_list.append(raw_captions[index*BATCH_SIZE + elem_in_batch])\n",
    "     \n",
    "    captions_batch = np.vstack(caption_list)\n",
    "    \n",
    "    save_array(base_path+batch_folder+captions_folder+'caption_'+str(format(index, \"06\"))+'_'+'.bc',\n",
    "               captions_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save indexed captions batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 27434.01it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_words = get_unique_words(raw_captions)\n",
    "VOCAB_SIZE = len(unique_words)\n",
    "(word2index, index2word) = get_index_word_dicts(unique_words)\n",
    "\n",
    "indexed_captions = []\n",
    "for index,raw_caption in tqdm(enumerate(raw_captions)):\n",
    "    indexed_caption = [word2index[caption_word] for caption_word in raw_caption.split()]\n",
    "    indexed_caption = sequence.pad_sequences([indexed_caption], maxlen=MAX_CAPTION_LEN,padding='post')\n",
    "    indexed_np_arr = np.asarray(np.squeeze(indexed_caption))\n",
    "    \n",
    "    indexed_captions.append(indexed_np_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 142.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(indexed_captions)/BATCH_SIZE)):\n",
    "    \n",
    "    indexed_caption_list = []\n",
    "    \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        indexed_caption = np.expand_dims(indexed_captions[index*BATCH_SIZE + elem_in_batch],axis=0)\n",
    "        indexed_caption_list.append(indexed_caption)\n",
    "        \n",
    "    indexed_captions_batch = np.vstack(indexed_caption_list)\n",
    "    \n",
    "    save_array(base_path + batch_folder + indexed_captions_folder + 'indexed_caption_'\n",
    "               + str(format(index, \"06\")) + '_' + '.bc',\n",
    "               indexed_captions_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save future words captions batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.86it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm((range(len(indexed_captions)/BATCH_SIZE))):\n",
    "\n",
    "    indexed_future_word_list = []\n",
    "        \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "\n",
    "        caption_indexed = indexed_captions[index*BATCH_SIZE + elem_in_batch]\n",
    "            \n",
    "        enhanced_caption_indexed = np.append(caption_indexed,[word2index[\"END\"]]) #hacky\n",
    "        word_2_next_word = []\n",
    "\n",
    "        for i in xrange(0,len(caption_indexed)):\n",
    "            caption_word_index = enhanced_caption_indexed[i]\n",
    "            future_word_index = enhanced_caption_indexed[i+1]\n",
    "            future_indexes = np.zeros(VOCAB_SIZE)\n",
    "            future_indexes[future_word_index] = 1\n",
    "\n",
    "            word_2_next_word.append(future_indexes)\n",
    "\n",
    "        words_2_next_word = np.vstack(word_2_next_word)\n",
    "        words_2_next_word = np.expand_dims(words_2_next_word,axis=0)\n",
    "        \n",
    "        indexed_future_word_list.append(words_2_next_word)\n",
    "    \n",
    "    indexed_future_words_batch = np.vstack(indexed_future_word_list)\n",
    "    \n",
    "    save_array(base_path+batch_folder+indexed_future_words_folder+'indexed_future_word_'+str(format(index, \"06\"))+'_'+'.bc', \n",
    "               indexed_future_words_batch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving other misc data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.save_obj(unique_words,base_path+batch_folder+misc_folder+\"unique_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.save_obj(word2index,base_path+batch_folder+misc_folder+\"word2index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc.save_obj(index2word,base_path+batch_folder+misc_folder+\"index2word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
