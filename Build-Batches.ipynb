{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n",
      "/opt/conda/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from tqdm import tqdm\n",
    "import preprocessing as preproc\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_path = \"/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/\"\n",
    "\n",
    "# train_path = save_path + \"train/\"\n",
    "# val_path = save_path + \"val/\"\n",
    "\n",
    "# images_vgg_4096_folder = \"images_vgg_4096/\"\n",
    "# captions_folder = \"captions/\"\n",
    "# indexed_captions_folder = \"indexed-captions/\"\n",
    "# batch_folder = \"batches/\"\n",
    "# indexed_future_words_folder = \"indexed-future-words/\"\n",
    "# misc_folder = \"misc/\"\n",
    "# general_datastruct_folder = \"general-datastruct/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = app_3_length_15_data_path\n",
    "base_path = path + train_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NR_TRAIN_INSTANCES = 82000\n",
    "BATCH_SIZE = 2048\n",
    "MAX_CAPTION_LEN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62735, 4096)\n"
     ]
    }
   ],
   "source": [
    "images_precomputed_vgg_features = preproc.read_serialized_np_arr(base_path+images_vgg_4096_folder+'vgg_features.bc'\n",
    "                                                                  ,nr_instances = NR_TRAIN_INSTANCES )\n",
    "\n",
    "print(images_precomputed_vgg_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62735\n"
     ]
    }
   ],
   "source": [
    "raw_captions = preproc.get_truncated_captions_from_batch(base_path + captions_folder, batch_nr = 0,\n",
    "                                                           nr_instances = NR_TRAIN_INSTANCES )\n",
    "\n",
    "print(len(raw_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7275\n"
     ]
    }
   ],
   "source": [
    "unique_words = preproc.load_obj(path+general_datastruct_folder+\"unique_words\")\n",
    "word2index = preproc.load_obj(path+general_datastruct_folder+\"word2index\")\n",
    "index2word = preproc.load_obj(path+general_datastruct_folder+\"index2word\")\n",
    "VOCAB_SIZE = len(unique_words)\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save img vgg features batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.07it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(images_precomputed_vgg_features) / BATCH_SIZE)):\n",
    "    img_vgg_feature_list = []\n",
    "    \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        img_vgg_feature = np.expand_dims(images_precomputed_vgg_features[index*BATCH_SIZE + elem_in_batch],axis=0)\n",
    "        img_vgg_feature_list.append(img_vgg_feature)\n",
    "        \n",
    "    img_vgg_batch = np.vstack(img_vgg_feature_list)\n",
    "    save_array(base_path + batch_folder + images_vgg_4096_folder + 'img_vgg_feature_' + str(format(index, \"06\"))\n",
    "               + '_' + '.bc',img_vgg_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save raw captions batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 106.84it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(raw_captions)/BATCH_SIZE)):\n",
    "    caption_list = []\n",
    "    \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        caption_list.append(raw_captions[index*BATCH_SIZE + elem_in_batch])\n",
    "     \n",
    "    captions_batch = np.vstack(caption_list)\n",
    "    \n",
    "    save_array(base_path+batch_folder+captions_folder+'caption_'+str(format(index, \"06\"))+'_'+'.bc',\n",
    "               captions_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save indexed captions batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexed_captions_folder = \"indexed-captions/\"\n",
    "indexed_future_words_folder = \"indexed-future-words/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62735it [00:01, 51277.93it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 151.39it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_captions = []\n",
    "for index,raw_caption in tqdm(enumerate(raw_captions)):\n",
    "    indexed_caption = [word2index[caption_word] for caption_word in raw_caption.split()]\n",
    "    indexed_caption = sequence.pad_sequences([indexed_caption], maxlen=MAX_CAPTION_LEN,padding='post')\n",
    "    indexed_np_arr = np.asarray(np.squeeze(indexed_caption))\n",
    "    \n",
    "    indexed_captions.append(indexed_np_arr)\n",
    "    \n",
    "    \n",
    "for index in tqdm(range(len(indexed_captions)/BATCH_SIZE)):\n",
    "    \n",
    "    indexed_caption_list = []\n",
    "    \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        indexed_caption = np.expand_dims(indexed_captions[index*BATCH_SIZE + elem_in_batch],axis=0)\n",
    "        indexed_caption_list.append(indexed_caption)\n",
    "        \n",
    "    indexed_captions_batch = np.vstack(indexed_caption_list)\n",
    "    \n",
    "    save_array(base_path + batch_folder + indexed_captions_folder + 'indexed_caption_'\n",
    "               + str(format(index, \"06\")) + '_' + '.bc',\n",
    "               indexed_captions_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save future words captions batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:07<01:42,  3.67s/it]"
     ]
    }
   ],
   "source": [
    "for index in tqdm((range(len(indexed_captions)/BATCH_SIZE))):\n",
    "\n",
    "    indexed_future_word_list = []\n",
    "        \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "\n",
    "        caption_indexed = indexed_captions[index*BATCH_SIZE + elem_in_batch]\n",
    "            \n",
    "        enhanced_caption_indexed = np.append(caption_indexed,[word2index[\"END\"]]) #hacky\n",
    "        word_2_next_word = []\n",
    "\n",
    "        for i in xrange(0,len(caption_indexed)):\n",
    "            caption_word_index = enhanced_caption_indexed[i]\n",
    "            future_word_index = enhanced_caption_indexed[i+1]\n",
    "            future_indexes = np.zeros(VOCAB_SIZE)\n",
    "            future_indexes[future_word_index] = 1\n",
    "\n",
    "            word_2_next_word.append(future_indexes)\n",
    "\n",
    "        words_2_next_word = np.vstack(word_2_next_word)\n",
    "        words_2_next_word = np.expand_dims(words_2_next_word,axis=0)\n",
    "        \n",
    "        indexed_future_word_list.append(words_2_next_word)\n",
    "    \n",
    "    indexed_future_words_batch = np.vstack(indexed_future_word_list)\n",
    "    \n",
    "    save_array(base_path+batch_folder+indexed_future_words_folder+'indexed_future_word_'+str(format(index, \"06\"))+'_'+'.bc', \n",
    "               indexed_future_words_batch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
