{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n",
      "/opt/conda/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from tqdm import tqdm\n",
    "import preprocessing as preproc\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = app_3_length_15_data_path\n",
    "base_path = path + val_folder\n",
    "\n",
    "NR_TRAIN_INSTANCES = 82000\n",
    "BATCH_SIZE = 2048\n",
    "MAX_CAPTION_LEN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28858, 4096)\n",
      "28858\n",
      "7275\n"
     ]
    }
   ],
   "source": [
    "images_precomputed_vgg_features = preproc.read_serialized_np_arr(base_path+images_vgg_4096_folder+'vgg_features.bc'\n",
    "                                                                  ,nr_instances = NR_TRAIN_INSTANCES )\n",
    "\n",
    "print(images_precomputed_vgg_features.shape)\n",
    "\n",
    "raw_captions = preproc.get_truncated_captions_from_batch(base_path + captions_folder, batch_nr = 0,\n",
    "                                                           nr_instances = NR_TRAIN_INSTANCES )\n",
    "\n",
    "print(len(raw_captions))\n",
    "\n",
    "unique_words = preproc.load_obj(path+general_datastruct_folder+\"unique_words\")\n",
    "word2index = preproc.load_obj(path+general_datastruct_folder+\"word2index\")\n",
    "index2word = preproc.load_obj(path+general_datastruct_folder+\"index2word\")\n",
    "VOCAB_SIZE = len(unique_words)\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28858it [00:00, 35942.26it/s]\n"
     ]
    }
   ],
   "source": [
    "prev_indexed_captions = []\n",
    "for index,raw_caption in tqdm(enumerate(raw_captions)):\n",
    "    indexed_caption = [word2index[caption_word] for caption_word in raw_caption.split()]\n",
    "    \n",
    "    #this is where the magic happens\n",
    "    indexed_caption.insert(0, indexed_caption[0])\n",
    "    indexed_caption = indexed_caption[:-1]\n",
    "    \n",
    "    indexed_caption = sequence.pad_sequences([indexed_caption], maxlen=MAX_CAPTION_LEN,padding='post')\n",
    "    indexed_np_arr = np.asarray(np.squeeze(indexed_caption))\n",
    "    \n",
    "    prev_indexed_captions.append(indexed_np_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexed_prev_captions_folder = \"indexed-prev-captions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 117.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(prev_indexed_captions)/BATCH_SIZE)):\n",
    "    \n",
    "    indexed_caption_list = []\n",
    "     \n",
    "    for elem_in_batch in range(BATCH_SIZE):\n",
    "        indexed_caption = np.expand_dims(prev_indexed_captions[index*BATCH_SIZE + elem_in_batch],axis=0)\n",
    "        indexed_caption_list.append(indexed_caption)\n",
    "        \n",
    "    indexed_captions_batch = np.vstack(indexed_caption_list)\n",
    "    \n",
    "    save_array(base_path + batch_folder + indexed_prev_captions_folder + 'indexed_prev_caption_'\n",
    "               + str(format(index, \"06\")) + '_' + '.bc',\n",
    "               indexed_captions_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
