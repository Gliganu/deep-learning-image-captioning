{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n",
      "/opt/conda/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "# from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "# from keras.utils import np_utils, generic_utils\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "# from keras.layers import Embedding,GRU,TimeDistributed,RepeatVector,Merge\n",
    "# from keras.preprocessing.text import one_hot\n",
    "# from keras.preprocessing import sequence\n",
    "\n",
    "import numpy as np\n",
    "# from vgg16 import Vgg16\n",
    "\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# import PIL.Image\n",
    "\n",
    "# import json\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "from utils import *\n",
    "# import cPickle as pickle\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "import collections\n",
    "\n",
    "import preprocessing as preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_path = full_data_path\n",
    "train_path = base_path + train_folder\n",
    "val_path = base_path + val_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_N_captions_sum(captions,N):\n",
    "    caption_lengths = [len(caption.split()) for caption in captions]\n",
    "    counter=collections.Counter(caption_lengths)\n",
    "    return sum([value for key,value in counter.iteritems() if key <= N])\n",
    "\n",
    "def get_unique_words(captions):\n",
    "    unique_words = []\n",
    "    words = [caption.split() for caption in captions]\n",
    "   \n",
    "    for word in words:\n",
    "        unique_words.extend(word)\n",
    "        \n",
    "    unique_words = list(set(unique_words))\n",
    "    \n",
    "    return unique_words\n",
    "\n",
    "def no_words_with_min_appearances(captions,min_no_of_occurences):\n",
    "    \n",
    "    sentences = [caption.split() for caption in captions]\n",
    "    words = []\n",
    "    for word in sentences:\n",
    "        words.extend(word)\n",
    "\n",
    "    counter=collections.Counter(words)\n",
    "    nr_words = len([_ for word,no_appearances in counter.most_common() if no_appearances >= min_no_of_occurences])\n",
    "    \n",
    "    return nr_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122050"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captions = preproc.get_captions_from_batch(train_path + captions_folder, batch_nr = 0)\n",
    "val_captions = preproc.get_captions_from_batch(val_path + captions_folder, batch_nr = 0)\n",
    "\n",
    "captions = list(train_captions) + list(val_captions)\n",
    "len(captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of captions having length less than X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions of length <= 9  ----> Sum = 863  => Percentage = 0.007071\n",
      "Captions of length <= 10  ----> Sum = 19621  => Percentage = 0.160762\n",
      "Captions of length <= 12  ----> Sum = 73007  => Percentage = 0.598173\n",
      "Captions of length <= 15  ----> Sum = 112702  => Percentage = 0.923408\n",
      "Captions of length <= 20  ----> Sum = 121009  => Percentage = 0.991471\n",
      "Captions of length <= 50  ----> Sum = 122049  => Percentage = 0.999992\n"
     ]
    }
   ],
   "source": [
    "totalSum = first_N_captions_sum(captions,500)\n",
    "\n",
    "for N in [9,10,12,15,20,50]:\n",
    "    firstN = first_N_captions_sum(captions,N)\n",
    "    print(\"Captions of length <= %d  ----> Sum = %d  => Percentage = %f\"%(N,firstN,firstN/float(totalSum)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Number of words having more appearances than X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22261.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = preproc.load_obj(base_path + general_datastruct_folder + \"unique_words\")\n",
    "allWords = float(len(unique_words))\n",
    "allWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_no = 1 app --> No of words = 22261  ---> Percentage = 1.000000\n",
      "Min_no = 2 app --> No of words = 11622  ---> Percentage = 0.522079\n",
      "Min_no = 3 app --> No of words = 8821  ---> Percentage = 0.396254\n",
      "Min_no = 5 app --> No of words = 6286  ---> Percentage = 0.282377\n",
      "Min_no = 10 app --> No of words = 4125  ---> Percentage = 0.185302\n",
      "Min_no = 100 app --> No of words = 946  ---> Percentage = 0.042496\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3ccf0a2a9e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnr_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_words_with_min_appearances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "for N in [1,2,3,5,10,100]:\n",
    "    nr_words = no_words_with_min_appearances(captions,N)\n",
    "    print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 1\n",
    "N = 2\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 3\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 5\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 10\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 100\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 500\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 5000\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Captions containing only common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_captions_len = 113093 app --> min_no_on_app = 2  ---> Percentage = 0.926612\n",
      "valid_captions_len = 108947 app --> min_no_on_app = 3  ---> Percentage = 0.892642\n",
      "valid_captions_len = 105651 app --> min_no_on_app = 4  ---> Percentage = 0.865637\n",
      "valid_captions_len = 93777 app --> min_no_on_app = 10  ---> Percentage = 0.768349\n",
      "valid_captions_len = 64546 app --> min_no_on_app = 50  ---> Percentage = 0.528849\n"
     ]
    }
   ],
   "source": [
    "total_length = len(captions)\n",
    "\n",
    "MIN_NO_OF_APP = 2\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n",
    "\n",
    "MIN_NO_OF_APP = 3\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n",
    "\n",
    "MIN_NO_OF_APP = 4\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n",
    "\n",
    "MIN_NO_OF_APP = 10\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n",
    "\n",
    "MIN_NO_OF_APP = 50\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
