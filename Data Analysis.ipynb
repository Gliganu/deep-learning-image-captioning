{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n",
      "/opt/conda/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers import Embedding,GRU,TimeDistributed,RepeatVector,Merge\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import numpy as np\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "from utils import *\n",
    "import cPickle as pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import collections\n",
    "\n",
    "import preprocessing as preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = \"/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/\"\n",
    "\n",
    "train_path = save_path + \"train/\"\n",
    "val_path = save_path + \"val/\"\n",
    "\n",
    "captions_folder = \"captions/\"\n",
    "general_datastruct_folder = \"general-datastruct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_N_captions_sum(captions,N):\n",
    "    caption_lengths = [len(caption.split()) for caption in captions]\n",
    "    counter=collections.Counter(caption_lengths)\n",
    "    return sum([value for key,value in counter.iteritems() if key <= N])\n",
    "\n",
    "def get_unique_words(captions):\n",
    "    unique_words = []\n",
    "    words = [caption.split() for caption in captions]\n",
    "   \n",
    "    for word in words:\n",
    "        unique_words.extend(word)\n",
    "        \n",
    "    unique_words = list(set(unique_words))\n",
    "    \n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/train/captions/captions_batch_0.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-05604eddba80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_captions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_captions_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcaptions_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_nr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_captions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_captions_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcaptions_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_nr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcaptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_captions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_captions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/docker/fastai-courses/deeplearning1/nbs/persistent/fast-ai-notebooks/deep-learning-image-captioning/preprocessing.pyc\u001b[0m in \u001b[0;36mget_captions_from_batch\u001b[0;34m(path, batch_nr)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_captions_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_nr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"captions_batch_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_nr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_truncated_captions_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_nr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnr_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/docker/fastai-courses/deeplearning1/nbs/persistent/coco/train/captions/captions_batch_0.p'"
     ]
    }
   ],
   "source": [
    "train_captions = preproc.get_captions_from_batch(train_path + captions_folder, batch_nr = 0)\n",
    "val_captions = preproc.get_captions_from_batch(val_path + captions_folder, batch_nr = 0)\n",
    "\n",
    "captions = train_captions + val_captions\n",
    "len(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalSum = first_N_captions_sum(captions,500)\n",
    "\n",
    "N = 9\n",
    "firstN = first_N_captions_sum(captions,N)\n",
    "print(\"Captions of length <= %d  ----> Sum = %d  => Percentage = %f\"%(N,firstN,firstN/float(totalSum)))\n",
    "\n",
    "N = 10\n",
    "firstN = first_N_captions_sum(captions,N)\n",
    "print(\"Captions of length <= %d  ---> Sum = %d => Percentage = %f\"%(N,firstN,firstN/float(totalSum)))\n",
    "\n",
    "N = 12\n",
    "firstN = first_N_captions_sum(captions,N)\n",
    "print(\"Captions of length <= %d  ---> Sum = %d => Percentage = %f\"%(N,firstN,firstN/float(totalSum)))\n",
    "\n",
    "N = 15\n",
    "firstN = first_N_captions_sum(captions,N)\n",
    "print(\"Captions of length <= %d  ---> Sum = %d => Percentage = %f\"%(N,firstN,firstN/float(totalSum)))\n",
    "\n",
    "N = 20\n",
    "firstN = first_N_captions_sum(captions,N)\n",
    "print(\"Captions of length <= %d  ---> Sum = %d => Percentage = %f\"%(N,firstN,firstN/float(totalSum)))\n",
    "\n",
    "N = 50\n",
    "firstN = first_N_captions_sum(captions,N)\n",
    "print(\"Captions of length <= %d  ---> Sum = %d => Percentage = %f\"%(N,firstN,firstN/float(totalSum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def no_words_with_min_appearances(captions,min_no_of_occurences):\n",
    "    \n",
    "    sentences = [caption.split() for caption in captions]\n",
    "    words = []\n",
    "    for word in sentences:\n",
    "        words.extend(word)\n",
    "\n",
    "    counter=collections.Counter(words)\n",
    "    nr_words = len([_ for word,no_appearances in counter.most_common() if no_appearances >= min_no_of_occurences])\n",
    "    \n",
    "    return nr_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_words = preproc.load_obj(save_path+general_datastruct_folder+\"unique_words\")\n",
    "allWords = float(len(unique_words))\n",
    "allWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 1\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 2\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 3\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 5\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 10\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 100\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 500\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))\n",
    "\n",
    "N = 5000\n",
    "nr_words = no_words_with_min_appearances(captions,N)\n",
    "print(\"Min_no = %d app --> No of words = %d  ---> Percentage = %f\"%(N,nr_words,float(nr_words)/allWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Captions containing only common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_length = len(train_mask_no_words)\n",
    "\n",
    "MIN_NO_OF_APP = 2\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n",
    "\n",
    "MIN_NO_OF_APP = 3\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n",
    "\n",
    "MIN_NO_OF_APP = 4\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n",
    "\n",
    "MIN_NO_OF_APP = 10\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n",
    "\n",
    "MIN_NO_OF_APP = 50\n",
    "nr_captions =  np.sum(preproc.compute_common_words_caption_mask(captions,min_no_of_app = MIN_NO_OF_APP))\n",
    "print(\"valid_captions_len = %d app --> min_no_on_app = %d  ---> Percentage = %f\"%(nr_captions,MIN_NO_OF_APP,float(nr_captions)/total_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
