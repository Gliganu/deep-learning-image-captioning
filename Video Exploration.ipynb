{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding,GRU,TimeDistributed,RepeatVector,Merge,BatchNormalization,Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Embedding,LSTM,GRU,TimeDistributed,RepeatVector,Merge,Input,merge,UpSampling2D\n",
    "from keras.preprocessing import sequence\n",
    "from keras import callbacks\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "import numpy as np\n",
    "from vgg16 import Vgg16\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils as utils\n",
    "\n",
    "import cPickle as pickle\n",
    "import string\n",
    "\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from numpy.random import random, permutation, randn, normal \n",
    "\n",
    "import os\n",
    "\n",
    "import preprocessing as preproc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nnModel as nnModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skvideo.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vc = skvideo.io.VideoCapture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_movie_mp4(image_array):\n",
    "    dpi = 72.0\n",
    "    xpixels, ypixels = image_array[0].shape[0], image_array[0].shape[1]\n",
    "    fig = plt.figure(figsize=(ypixels/dpi, xpixels/dpi), dpi=dpi)\n",
    "    im = plt.figimage(image_array[0])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_array(image_array[i])\n",
    "        return (im,)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(image_array), interval = 50)\n",
    "    display(HTML(anim.to_html5_video()))\n",
    "\n",
    "def resize(pic):\n",
    "    return np.asarray(Image.fromarray(np.uint8(pic)).resize((224, 224), Image.NEAREST))\n",
    "\n",
    "def read_video_frames(filename):\n",
    "    vid = imageio.get_reader(filename,  'ffmpeg')\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    for i, im in enumerate(vid):\n",
    "        im = np.asarray(im)\n",
    "        im = np.expand_dims(im,axis=0)\n",
    "        frames.append(im)\n",
    "    \n",
    "    frames = np.vstack(frames)\n",
    "    \n",
    "    return [resize(pic) for pic in frames]\n",
    "\n",
    "def get_mp4_vid_frames(path):\n",
    "    \n",
    "    frames = read_video_frames(filename)\n",
    "\n",
    "    frames = np.transpose(np.asarray(frames),(0,3,1,2))\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "horse_path = \"./horse.mp4\"\n",
    "video_frames = get_mp4_vid_frames(horse_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287, 3, 224, 224)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_frames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = data_path+\"app-100-length-15/\"\n",
    "\n",
    "(unique_words, word2index, index2word) = utils.load_language_data_structures(base_path + general_datastruct_folder)\n",
    "VOCAB_SIZE = len(unique_words)\n",
    "MAX_CAPTION_LEN = 15\n",
    "EMB_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found = 840\n",
      "Not found = 8\n"
     ]
    }
   ],
   "source": [
    "emb = nnModel.get_embeddings(index2word, VOCAB_SIZE, EMB_SIZE)\n",
    "model = nnModel.build_model(emb,MAX_CAPTION_LEN, VOCAB_SIZE, EMB_SIZE)\n",
    "\n",
    "model.load_weights(save_path + models_folder+\"big/\" +'app_100_length_15_past_word_20_epoch_300d_gru_2x1048_big.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  9.93it/s]\n"
     ]
    }
   ],
   "source": [
    "(_,video_captions) = nnModel.make_prediction_on_dataset(video_frames,model,word2index,index2word,MAX_CAPTION_LEN,0,100)\n",
    "video_captions = list(set(video_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'A horse is grazing in a field with a fence behind it',\n",
       " u'A horse standing in a field with other horses',\n",
       " u'A horse standing in a field with a fence behind it',\n",
       " u'A horse standing in a field with a horse behind it',\n",
       " u'A horse standing in a field with a fence in the background',\n",
       " u'A horse is grazing in a field of grass']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import videoExplorer as vidExplorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search frames by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'videoExplorer' from 'videoExplorer.py'>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(vidExplorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_search_word = \"fence\"\n",
    "(found_images,found_captions,found_indexes) = vidExplorer.search_video_by(video_search_word,video_frames,video_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
