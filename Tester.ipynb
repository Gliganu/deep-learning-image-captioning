{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n",
      "/opt/conda/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import preprocessing as preproc\n",
    "from utils import *\n",
    "import collections\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetricsData(object):\n",
    "\n",
    "    def __init__(self,word,appearances,metrics_dict):\n",
    "        self.word = word\n",
    "        self.appearances = appearances\n",
    "        self.metrics_dict = metrics_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def status((groundTruthValue,predictedValue)):\n",
    "    if(groundTruthValue):\n",
    "        if(predictedValue):\n",
    "            return \"TP\"\n",
    "        return \"FN\"\n",
    "    \n",
    "    if(predictedValue):\n",
    "        return \"FP\"\n",
    "    \n",
    "    return \"TN\"\n",
    "\n",
    "def get_metrics(true_word_mask,predicted_word_mask):\n",
    "    truth2predictedArr = zip(true_word_mask,predicted_word_mask)\n",
    "    statusArr = [status(truth2predicted) for truth2predicted in truth2predictedArr]\n",
    "    counter = collections.defaultdict(int,collections.Counter(statusArr).most_common())\n",
    "    \n",
    "    tp = counter['TP']\n",
    "    fp = counter['FP']\n",
    "    tn = counter['TN']\n",
    "    fn = counter['FN']\n",
    "    \n",
    "    precision = float(tp)/max(1,(tp+fp))\n",
    "    recall = float(tp)/max(1,(tp+fn))\n",
    "\n",
    "    return {\"precision\":precision,\"recall\":recall}\n",
    "\n",
    "def containsWord(sentence, word):\n",
    "    return word in sentence\n",
    "\n",
    "def get_word_mask(captions,word):\n",
    "    return [containsWord(caption, word) for caption in captions]\n",
    "\n",
    "def computeMetricsData(word):\n",
    "    true_word_mask = get_word_mask(true_captions,metric_word)\n",
    "    predicted_word_mask = get_word_mask(predicted_captions,metric_word)\n",
    "\n",
    "    nr_instances = sum(true_word_mask)\n",
    "    metrics_dict = get_metrics(true_word_mask,predicted_word_mask)\n",
    "\n",
    "    return MetricsData(metric_word,nr_instances,metrics_dict)\n",
    "\n",
    "def displayMetrics(metric_data_arr):\n",
    "    \n",
    "    for metric_data in metric_data_arr:\n",
    "       \n",
    "        print(metric_data.word+\" => \"+str(metric_data.appearances)+\" instances\")\n",
    "        print(\"\\tPrecision: \"+str(metric_data.metrics_dict[\"precision\"]))\n",
    "        print(\"\\tRecall: \"+str(metric_data.metrics_dict[\"recall\"]))\n",
    "        print(\"\")\n",
    "\n",
    "def displayAggMetrics(metric_data_arr):\n",
    "    total_instances = sum([metric_data.appearances for metric_data in metric_data_arr])\n",
    "    \n",
    "    for key in metric_data_arr[0].metrics_dict:\n",
    "        metric_sum = sum([metric_data.appearances*metric_data.metrics_dict[key] for metric_data in metric_data_arr])        \n",
    "        weighted_metric = float(metric_sum)/total_instances\n",
    "        print(\"Weighted \"+str(key)+str(\": \") + str(weighted_metric))\n",
    "        \n",
    "def bleu_score_metric(reality, prediction):\n",
    "    return nltk.translate.bleu_score.sentence_bleu([reality], prediction)\n",
    "\n",
    "def compute_bleu_score_metric(predicted_captions, real_captions):\n",
    "    real_captions = reduce(list.__add__, [list(real_caption) for real_caption in tqdm(real_captions)])\n",
    "    bleu_scores = [bleu_score_metric(real_captions[i], predicted_captions[i]) for i in tqdm(range(len(predicted_captions)))]\n",
    "    return np.average(bleu_scores)\n",
    "\n",
    "def get_nr_repetitions(predicted_caption):\n",
    "    counter = preproc.most_common_words([predicted_caption])\n",
    "    repetition_values = [nr_app for (word,nr_app) in counter if nr_app > 1]\n",
    "    return sum(repetition_values) / 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_path = app_3_length_15_data_path\n",
    "\n",
    "train_path = base_path + train_folder\n",
    "val_path = base_path + val_folder\n",
    "\n",
    "test_indexed_captions_path = base_path + val_folder + batch_folder + indexed_captions_folder\n",
    "test_raw_captions_path = base_path + val_folder + batch_folder+captions_folder\n",
    "\n",
    "specific_captions = \"app_3_length_15_past_word_70_epoch_predicted_captions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(test_captions_raw,_) = preproc.get_captions_raw_and_indexed(test_raw_captions_path,test_indexed_captions_path)\n",
    "true_captions = [list(test_caption_raw)[0] for test_caption_raw in test_captions_raw]\n",
    "\n",
    "max_size = len(true_captions)\n",
    "predicted_captions = preproc.load_obj(val_path+predictions_folder+specific_captions)[:max_size]\n",
    "\n",
    "\n",
    "print(len(true_captions))\n",
    "print(len(predicted_captions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific words metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric_words = ['tennis','snow','train','cat','red','yellow','food','kitchen']\n",
    "metric_data_arr = [computeMetricsData(metric_word) for metric_word in tqdm(metric_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "displayMetrics(metric_data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "displayAggMetrics(metric_data_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# All words metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = dict(preproc.most_common_words(true_captions)).keys()\n",
    "all_metric_data_arr = [computeMetricsData(metric_word) for metric_word in tqdm(all_words)]\n",
    "displayAggMetrics(all_metric_data_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BLEU Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_bleu_score_metric(predicted_captions,true_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repetition Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_nr_repetitions = sum([get_nr_repetitions(predicted_caption) for predicted_caption in tqdm(predicted_captions)])\n",
    "total_nr_words = sum(len(caption.split()) for caption in tqdm(predicted_captions))\n",
    "repetition_score = float(total_nr_repetitions) / total_nr_words\n",
    "\n",
    "print(\"Total nr repetitions = \"+str(total_nr_repetitions))\n",
    "print(\"Total nr words = \"+str(total_nr_words))\n",
    "print(\"Repetition score = \"+str(repetition_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
